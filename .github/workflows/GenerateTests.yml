name: Generate Jest Tests - Improved
on:
  # This line enables manual triggering of this workflow.
  workflow_dispatch:

defaults:
  run:
    #working-directory: app/client
    shell: bash

jobs:
  setup:
    runs-on: ubuntu-latest
    steps:
      - name: "Start of workflow"
        run: |
            echo "Starting the workflow"
        
      - name: "Checkout code"
        uses: actions/checkout@v2
        with:
          fetch-depth: 0

      - name: Get changed files in the client folder
        id: changed-files-specific
        uses: tj-actions/changed-files@v41
        with:
          files: "app/client/**"
          base_sha: "release"
    
      - name: Run step if any file(s) in the client folder change
        if: steps.changed-files-specific.outputs.any_changed == 'true'
        env:
          ALL_CHANGED_FILES: ${{ steps.changed-files-specific.outputs.all_changed_files }}
        run: |
          for file in ${ALL_CHANGED_FILES}; do
            echo "$file was changed"
          done
   
      - name: Install jest-gen-test
        run: yarn add jest-test-gen
    
      - name: Generate Tests
        if: steps.changed-files-specific.outputs.any_changed == 'true'
        env:
          ALL_CHANGED_FILES: ${{ steps.changed-files-specific.outputs.all_changed_files }}
        run: |
          for file in ${ALL_CHANGED_FILES}; do
            testfile=`echo $file|sed 's/.ts/.generated.test.ts/g'`
            yarn run jest-test-gen $file
            echo $testfile >> generated_test_files.txt
          done
        # git ignore yarn.lock

        # Step 1: Run Unit Tests on Generated Files
      - name: Run unit tests on generated files
        id: run_tests
        run: |
          while IFS= read -r testfile; do
            yarn test "$testfile" || echo "$testfile" >> failed_tests.txt
          done < generated_test_files.txt
        continue-on-error: true  # Continue even if tests fail to capture results

       # Step 2: Get Failed Tests
      - name: Capture failed test cases
        id: failed_tests
        run: |
          if [ -f failed_tests.txt ]; then
            failed_tests=$(cat failed_tests.txt | jq -R -s -c 'split("\n")[:-1]')
            echo "::set-output name=failed_tests::$failed_tests"
          else
            echo "::set-output name=failed_tests::[]"
          fi
      - name: Set up Python
        uses: actions/setup-python@v2
        with:
          python-version: '3.x'

      - name: Install OpenAI package
        run: pip install openai

      - name: Add OpenAI API Key
        run: echo "OPENAI_API_KEY=${{ secrets.OPENAI_API_KEY }}" >> $GITHUB_ENV

      - name: Fix failing tests
        run: |
          cp /home/runner/work/appsmith/appsmith/.github/workflows/scripts/fix_failing_tests.py ./
          python fix_failing_tests.py
      
      - name: Run fixed tests
        id: run__failed_tests
        run: |
          while IFS= read -r failed_tests; do
            yarn test "$testfile" || echo "$testfile" >> failed_tests.txt
          done < generated_test_files.txt
        continue-on-error: true

    # Commit newly generated test files
      - name: Commit generated test files
        if: steps.changed-files-specific.outputs.any_changed == 'true'
        run: |
           git config --global user.email "yatin@appsmith.com"
           git config --global user.name "github-actions[bot]"
           git add .
           git reset -- package.json
           git reset -- yarn.lock
           git commit -m "chore:generate tests for changed files"
           git push
